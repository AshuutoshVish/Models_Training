{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":11157946,"sourceType":"datasetVersion","datasetId":6961980}],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import time\nimport torch\nimport numpy as np\nimport pandas as pd\nimport torch.nn as nn\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.preprocessing import LabelEncoder, OrdinalEncoder, OneHotEncoder, StandardScaler, FunctionTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn import set_config\n\nfrom torchmetrics import Accuracy\nfrom torch.utils.data import Dataset, DataLoader\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-26T06:30:50.641586Z","iopub.execute_input":"2025-03-26T06:30:50.641952Z","iopub.status.idle":"2025-03-26T06:30:50.647321Z","shell.execute_reply.started":"2025-03-26T06:30:50.641923Z","shell.execute_reply":"2025-03-26T06:30:50.646367Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df=pd.read_csv('/kaggle/input/byjus-data-clean/Byjus.csv')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-26T06:30:50.662354Z","iopub.execute_input":"2025-03-26T06:30:50.662558Z","iopub.status.idle":"2025-03-26T06:30:50.736323Z","shell.execute_reply.started":"2025-03-26T06:30:50.662541Z","shell.execute_reply":"2025-03-26T06:30:50.735573Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-26T06:30:50.737565Z","iopub.execute_input":"2025-03-26T06:30:50.737788Z","iopub.status.idle":"2025-03-26T06:30:50.742687Z","shell.execute_reply.started":"2025-03-26T06:30:50.737770Z","shell.execute_reply":"2025-03-26T06:30:50.741690Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def convert_age(X):\n    X = X.copy()\n    X['age'] = pd.to_numeric(X['age'].astype(str).str.replace('+', '', regex=False), errors='coerce')\n    X['age'] = pd.cut(X['age'], \n                      bins=[18, 22, 25, 28, 32, 35, float('inf')],\n                      labels=['18-22', '23-25', '26-28', '29-32', '33-35', '35+'], \n                      right=True)\n    return X","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-26T06:30:50.744748Z","iopub.execute_input":"2025-03-26T06:30:50.745028Z","iopub.status.idle":"2025-03-26T06:30:50.755179Z","shell.execute_reply.started":"2025-03-26T06:30:50.745008Z","shell.execute_reply":"2025-03-26T06:30:50.754328Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Education mapping\neducation_mapping = {'engineering & technology': ['b.e / b-tech', 'bca/mca','m.e / m-tech', 'b.voc in networking and mobile applications', \n                                                  'b.arch', 'b.eng', 'b-tech', 'cse', 'bsc bedd - computer science', 'bachelors in engineering',\n                                                  'food technology', 'biotechnology', 'masters in data science','mtech', 'btech', 'mca'],\n                     \n                     'bsc/msc': ['bsc', 'bsc or msc', 'bachelors in philosophy'],\n                     'commerce & business': ['mba', 'b.com (bachelor of commerce)', 'b.com', 'b.comm', 'bba', 'bbm', 'bms', 'bachelor of business economics',\n                                             'bcom computers','bms marketing', 'pgdm banking','bcom', 'bba or bbm', 'master in management'],\n                     \n                     'arts & humanities': ['ba', 'ba/ma', 'ma', 'bachelor mass communication', 'bachelors in design', 'bachelor of social work', 'bachelor in eco'],\n                     'healthcare & medicine': ['b.pharma', 'med', 'bpharma', 'bds', 'b.physiotherapist', 'mbbs', 'pharma d', 'b -pharm', 'bachelor in medical lab', 'bachelor in dental'],\n                     'social sciences': ['masters in social work', 'msw', 'masters in clinical psychology', 'masters in social science', 'masters in sociology'],\n                     'diplomas & certifications': ['pgdm', 'pgdca', 'diploma', 'post graduation diploma', 'pgdf'],\n                     'phd & doctorate': ['phd', 'doctorate',  'm.phil  2020'],\n                     'vocational/technical': ['b.voc', 'vocational', 'bachelor of vocational','b voc - banking & finance'],\n                     'hospitality & tourism': ['hotel management', 'masters in hospitality', 'tourism']}\n\ndef edu_function(degree):\n    degree = str(degree).lower()\n    for category, keywords in education_mapping.items():\n        for keyword in keywords:\n            if keyword.lower() in degree:\n                return category\n    return 'Other'\n\ndef categorize_degree(X):\n    X = X.copy()\n    X['Education'] = X['Education'].str.lower().fillna('Other')\n    X['Education'] = X['Education'].apply(edu_function)\n    return X","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-26T06:30:50.756445Z","iopub.execute_input":"2025-03-26T06:30:50.756751Z","iopub.status.idle":"2025-03-26T06:30:50.769340Z","shell.execute_reply.started":"2025-03-26T06:30:50.756719Z","shell.execute_reply":"2025-03-26T06:30:50.768487Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"for col in df.columns:\n    if df[col].nunique()>10:\n        continue\n    print(f\"{col}----{df[col].nunique()}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-26T06:30:50.770328Z","iopub.execute_input":"2025-03-26T06:30:50.770594Z","iopub.status.idle":"2025-03-26T06:30:50.826557Z","shell.execute_reply.started":"2025-03-26T06:30:50.770575Z","shell.execute_reply":"2025-03-26T06:30:50.825862Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def label_encoder(X):\n    X = X.copy()\n    label_encoders = {}\n    categorical_cols = ['gender',\n                        'marital_status',\n                        'interview_mode', \n                        'mother_tongue_influence_in_english',\n                        'Anyone_spoken_before_applying', \n                        'currently_employed',\n                        'candidate_status']\n\n    for col in categorical_cols:\n        X[col] = X[col].fillna('Unknown')\n        le = LabelEncoder()\n        X[col] = le.fit_transform(X[col])\n        label_encoders[col] = le\n    return X","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-26T06:30:50.827264Z","iopub.execute_input":"2025-03-26T06:30:50.827544Z","iopub.status.idle":"2025-03-26T06:30:50.832205Z","shell.execute_reply.started":"2025-03-26T06:30:50.827515Z","shell.execute_reply":"2025-03-26T06:30:50.831198Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df['interview_verdict'] = df['interview_verdict'].replace({'Premium Select': 'Select', 'Borderline Select': 'Select', 'Borderline Reject': 'Reject'})","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-26T06:30:50.833023Z","iopub.execute_input":"2025-03-26T06:30:50.833620Z","iopub.status.idle":"2025-03-26T06:30:50.847683Z","shell.execute_reply.started":"2025-03-26T06:30:50.833572Z","shell.execute_reply":"2025-03-26T06:30:50.846990Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Label encode the target\nle_verdict = LabelEncoder()\ndf['interview_verdict'] = le_verdict.fit_transform(df['interview_verdict'])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-26T06:30:50.848477Z","iopub.execute_input":"2025-03-26T06:30:50.848778Z","iopub.status.idle":"2025-03-26T06:30:50.860076Z","shell.execute_reply.started":"2025-03-26T06:30:50.848750Z","shell.execute_reply":"2025-03-26T06:30:50.859398Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"numerical_cols = ['confidence_based_on_introduction_(english)',\n                  'confidence_based_on_the_topic_given__',\n                  'confidence_based_on_the_ppt_question',\n                  'confidence_based_on_the_sales_scenario',\n                  'structured_thinking_(in_regional_only)',\n                  'structured_thinking_based_on_the_ppt_question',\n                  'structured_thinking(_call_pitch)',\n                  'regional_fluency_based_on_the_topic_given__',\n                  'regional_fluency_based_on_the_ppt_question',\n                  'regional_fluency_based_on_the__sales_scenario',\n                  'confidence_score',\n                  'structured_thinking_score',\n                  'regional_fluency_score',\n                  'total_score'\n                 ]\n\ncategorical_cols = ['Education',\n                    'gender',\n                    'marital_status',\n                    'interview_mode',\n                    'mother_tongue_influence_in_english',\n                    'Anyone_spoken_before_applying',\n                    'currently_employed',\n                    'candidate_status', \n                    'candidate_is_willing_to_relocate',\n                    'last_fixed_ctc_(lakhs)', \n                    'experience_in_months',\n                    'what_was_the_type_of_role?',\n                    'how_many_slides_candidate_have_submitted_in_ppt?', \n                    'role_acceptance', \n                    'age']\n\npreprocessing_pipeline = Pipeline([('convert_age', FunctionTransformer(convert_age, validate=False)),\n                                   ('categorize_education', FunctionTransformer(categorize_degree, validate=False)),\n                                   ('label_encoder', FunctionTransformer(label_encoder, validate=False)),\n                                   ('encode_scale', ColumnTransformer(transformers=[\n                                       ('onehot', OneHotEncoder(sparse_output=False, drop='first'), categorical_cols),        #  One-hot encode categorical features\n                                       ('scaler', StandardScaler(), numerical_cols)                                           #  StandardScaler for all numerical columns\n                                   ], remainder='passthrough'))\n                                  ])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-26T06:30:50.862348Z","iopub.execute_input":"2025-03-26T06:30:50.862567Z","iopub.status.idle":"2025-03-26T06:30:50.871515Z","shell.execute_reply.started":"2025-03-26T06:30:50.862549Z","shell.execute_reply":"2025-03-26T06:30:50.870772Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Display the pipeline diagram\nset_config(display='diagram')\npreprocessing_pipeline","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-26T06:30:50.873065Z","iopub.execute_input":"2025-03-26T06:30:50.873346Z","iopub.status.idle":"2025-03-26T06:30:50.909363Z","shell.execute_reply.started":"2025-03-26T06:30:50.873318Z","shell.execute_reply":"2025-03-26T06:30:50.908531Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Splitting the data\nX = df.drop(columns=['interview_verdict']).copy()\ny = df['interview_verdict']","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-26T06:30:50.910093Z","iopub.execute_input":"2025-03-26T06:30:50.910320Z","iopub.status.idle":"2025-03-26T06:30:50.927024Z","shell.execute_reply.started":"2025-03-26T06:30:50.910302Z","shell.execute_reply":"2025-03-26T06:30:50.925760Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-26T06:30:50.927937Z","iopub.execute_input":"2025-03-26T06:30:50.928182Z","iopub.status.idle":"2025-03-26T06:30:50.937734Z","shell.execute_reply.started":"2025-03-26T06:30:50.928164Z","shell.execute_reply":"2025-03-26T06:30:50.936829Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"preprocessing_pipeline.fit(X_train, y_train)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-26T06:30:50.938336Z","iopub.execute_input":"2025-03-26T06:30:50.938557Z","iopub.status.idle":"2025-03-26T06:30:51.101994Z","shell.execute_reply.started":"2025-03-26T06:30:50.938538Z","shell.execute_reply":"2025-03-26T06:30:51.101095Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"X_train.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-26T06:30:51.102921Z","iopub.execute_input":"2025-03-26T06:30:51.103234Z","iopub.status.idle":"2025-03-26T06:30:51.107886Z","shell.execute_reply.started":"2025-03-26T06:30:51.103207Z","shell.execute_reply":"2025-03-26T06:30:51.107031Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Fit and transform with pipeline\nX_train_processed = preprocessing_pipeline.fit_transform(X_train, y_train)\nX_test_processed = preprocessing_pipeline.transform(X_test)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-26T06:30:51.108724Z","iopub.execute_input":"2025-03-26T06:30:51.108944Z","iopub.status.idle":"2025-03-26T06:30:51.295675Z","shell.execute_reply.started":"2025-03-26T06:30:51.108920Z","shell.execute_reply":"2025-03-26T06:30:51.294965Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"X_train_processed.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-26T06:30:51.296433Z","iopub.execute_input":"2025-03-26T06:30:51.296658Z","iopub.status.idle":"2025-03-26T06:30:51.301687Z","shell.execute_reply.started":"2025-03-26T06:30:51.296640Z","shell.execute_reply":"2025-03-26T06:30:51.300946Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Working on NN","metadata":{}},{"cell_type":"code","source":"# Convert to NumPy array and float32\ny_train_array = np.array(y_train).astype(np.float32)\ny_test_array = np.array(y_test).astype(np.float32)\n\n# Convert the preprocessed data into PyTorch tensors\nX_train_tensor = torch.tensor(X_train_processed, dtype=torch.float32)\nX_test_tensor = torch.tensor(X_test_processed, dtype=torch.float32)\n\n# Convert the target variables into PyTorch tensors\ny_train_tensor = torch.tensor(y_train_array, dtype=torch.float32)\ny_test_tensor = torch.tensor(y_test_array, dtype=torch.float32)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-26T06:30:51.302532Z","iopub.execute_input":"2025-03-26T06:30:51.302840Z","iopub.status.idle":"2025-03-26T06:30:51.316211Z","shell.execute_reply.started":"2025-03-26T06:30:51.302810Z","shell.execute_reply":"2025-03-26T06:30:51.315436Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Confirm the shapes\nprint(f\"X_train_tensor shape: {X_train_tensor.shape}, y_train_tensor shape: {y_train_tensor.shape}\")\nprint(f\"X_test_tensor shape: {X_test_tensor.shape}, y_test_tensor shape: {y_test_tensor.shape}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-26T06:30:51.316839Z","iopub.execute_input":"2025-03-26T06:30:51.317071Z","iopub.status.idle":"2025-03-26T06:30:51.329095Z","shell.execute_reply.started":"2025-03-26T06:30:51.317051Z","shell.execute_reply":"2025-03-26T06:30:51.328276Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class CustomDataset(Dataset):\n    def __init__(self, features, labels):\n        self.features = features\n        self.labels = labels\n\n    def __len__(self):\n        return len(self.labels)\n\n    def __getitem__(self, idx):\n        return self.features[idx], self.labels[idx]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-26T06:30:51.330134Z","iopub.execute_input":"2025-03-26T06:30:51.330421Z","iopub.status.idle":"2025-03-26T06:30:51.343042Z","shell.execute_reply.started":"2025-03-26T06:30:51.330393Z","shell.execute_reply":"2025-03-26T06:30:51.342331Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from torch.utils.data import DataLoader\n\n# Create dataset instances\ntrain_dataset = CustomDataset(X_train_tensor, y_train_tensor)\ntest_dataset = CustomDataset(X_test_tensor, y_test_tensor)\n\n# Define DataLoader\nbatch_size = 64\ntrain_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\ntest_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-26T06:30:51.343936Z","iopub.execute_input":"2025-03-26T06:30:51.344221Z","iopub.status.idle":"2025-03-26T06:30:51.359558Z","shell.execute_reply.started":"2025-03-26T06:30:51.344178Z","shell.execute_reply":"2025-03-26T06:30:51.358793Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch.nn as nn\nclass CandidateRankingModel(nn.Module):\n    def __init__(self, input_dim):\n        super(CandidateRankingModel, self).__init__()\n        self.fc1 = nn.Linear(input_dim, 128)\n        self.bn1 = nn.BatchNorm1d(128)\n        self.fc2 = nn.Linear(128, 64)\n        self.bn2 = nn.BatchNorm1d(64)\n        self.fc3 = nn.Linear(64, 1)\n        self.dropout = nn.Dropout(0.3)\n        self.relu = nn.ReLU()\n    \n    def forward(self, x):\n        x = self.relu(self.bn1(self.fc1(x)))\n        x = self.dropout(x)\n        x = self.relu(self.bn2(self.fc2(x)))\n        x = torch.sigmoid(self.fc3(x))\n        return x","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-26T06:30:51.360404Z","iopub.execute_input":"2025-03-26T06:30:51.360628Z","iopub.status.idle":"2025-03-26T06:30:51.374502Z","shell.execute_reply.started":"2025-03-26T06:30:51.360606Z","shell.execute_reply":"2025-03-26T06:30:51.373825Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Instantiate the model\ninput_dim = X_train_tensor.shape[1]\nmodel = CandidateRankingModel(input_dim)\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel.to(device)\n\ncriterion = nn.BCELoss()  # Binary Cross-Entropy Loss\noptimizer = torch.optim.Adam(model.parameters(), lr=0.0001)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-26T06:30:51.375245Z","iopub.execute_input":"2025-03-26T06:30:51.375480Z","iopub.status.idle":"2025-03-26T06:30:51.389061Z","shell.execute_reply.started":"2025-03-26T06:30:51.375461Z","shell.execute_reply":"2025-03-26T06:30:51.388393Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"input_dim","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-26T06:30:51.389733Z","iopub.execute_input":"2025-03-26T06:30:51.389957Z","iopub.status.idle":"2025-03-26T06:30:51.402724Z","shell.execute_reply.started":"2025-03-26T06:30:51.389936Z","shell.execute_reply":"2025-03-26T06:30:51.401944Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Check if model and data pipeline are working correctly\nmodel.train()\nfor batch_X, batch_y in train_loader:\n    batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n    \n    # Forward pass\n    outputs = model(batch_X)\n    print(\"Batch shape:\", batch_X.shape)\n    print(\"Output shape:\", outputs.shape)\n    print(\"Sample output:\", outputs[:5])\n    \n    break","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-26T06:30:51.403543Z","iopub.execute_input":"2025-03-26T06:30:51.403813Z","iopub.status.idle":"2025-03-26T06:30:51.420839Z","shell.execute_reply.started":"2025-03-26T06:30:51.403787Z","shell.execute_reply":"2025-03-26T06:30:51.420173Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def train(model, train_loader, criterion, optimizer, device):\n    model.train()\n    running_loss = 0.0\n    all_labels = []\n    all_preds = []\n\n    for batch_X, batch_y in train_loader:\n        batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n\n        optimizer.zero_grad()\n        outputs = model(batch_X)\n\n        # Reshape target to match the output shape\n        batch_y = batch_y.view(-1, 1)\n\n        # Compute loss\n        loss = criterion(outputs, batch_y)\n        loss.backward()\n        optimizer.step()\n\n        running_loss += loss.item()\n\n        # Store predictions and labels for metrics calculation\n        preds = (outputs >= 0.5).float()  # Threshold at 0.5 for binary classification\n        all_preds.extend(preds.cpu().detach().numpy())\n        all_labels.extend(batch_y.cpu().detach().numpy())\n\n    avg_loss = running_loss / len(train_loader)\n\n    # Calculate metrics\n    accuracy = accuracy_score(all_labels, all_preds)\n    precision = precision_score(all_labels, all_preds)\n    recall = recall_score(all_labels, all_preds)\n    f1 = f1_score(all_labels, all_preds)\n    auc_roc = roc_auc_score(all_labels, all_preds)\n\n    return avg_loss, accuracy, precision, recall, f1, auc_roc\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-26T06:30:51.423535Z","iopub.execute_input":"2025-03-26T06:30:51.423774Z","iopub.status.idle":"2025-03-26T06:30:51.430687Z","shell.execute_reply.started":"2025-03-26T06:30:51.423755Z","shell.execute_reply":"2025-03-26T06:30:51.429911Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def evaluate(model, test_loader, criterion, device):\n    model.eval()\n    running_loss = 0.0\n    all_labels = []\n    all_preds = []\n\n    with torch.no_grad():\n        for batch_X, batch_y in test_loader:\n            batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n\n            outputs = model(batch_X)\n\n            # Reshape target to match the output shape\n            batch_y = batch_y.view(-1, 1)\n\n            loss = criterion(outputs, batch_y)\n            running_loss += loss.item()\n\n            preds = (outputs >= 0.5).float()\n            all_preds.extend(preds.cpu().detach().numpy())\n            all_labels.extend(batch_y.cpu().detach().numpy())\n\n    avg_loss = running_loss / len(test_loader)\n\n    # Calculate metrics\n    accuracy = accuracy_score(all_labels, all_preds)\n    precision = precision_score(all_labels, all_preds)\n    recall = recall_score(all_labels, all_preds)\n    f1 = f1_score(all_labels, all_preds)\n    auc_roc = roc_auc_score(all_labels, all_preds)\n\n    return avg_loss, accuracy, precision, recall, f1, auc_roc","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-26T06:30:51.431824Z","iopub.execute_input":"2025-03-26T06:30:51.432139Z","iopub.status.idle":"2025-03-26T06:30:51.447763Z","shell.execute_reply.started":"2025-03-26T06:30:51.432112Z","shell.execute_reply":"2025-03-26T06:30:51.447064Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_losses = []\ntest_losses = []\ntrain_accuracies = []\ntest_accuracies = []\ntrain_precisions = []\ntest_precisions = []\ntrain_recalls = []\ntest_recalls = []\ntrain_f1_scores = []\ntest_f1_scores = []\ntrain_auc_roc = [] \ntest_auc_roc = []\n\ntorch.manual_seed(42)\nepochs = 30\nstart_time = time.time()\n\nfor epoch in range(1, epochs + 1):\n    train_loss, train_accuracy, train_precision, train_recall, train_f1_score, train_auc_roc_value = train(model, train_loader, criterion, optimizer, device)\n    test_loss, test_accuracy, test_precision, test_recall, test_f1_score, test_auc_roc_value = evaluate(model, test_loader, criterion, device)\n\n    # Store metrics for plotting\n    train_losses.append(train_loss)\n    test_losses.append(test_loss)\n    train_accuracies.append(train_accuracy)\n    test_accuracies.append(test_accuracy)\n    train_precisions.append(train_precision)\n    test_precisions.append(test_precision)\n    train_recalls.append(train_recall)\n    test_recalls.append(test_recall)\n    train_f1_scores.append(train_f1_score)\n    test_f1_scores.append(test_f1_score)\n    train_auc_roc.append(train_auc_roc_value)\n    test_auc_roc.append(test_auc_roc_value)\n\n    # Print epoch results\n    print(\"Training Started...!!\")\n    print(f\"\\nEpoch {epoch}/{epochs}\")\n    print(f\"Train Loss: {train_loss:.4f} | Test Loss: {test_loss:.4f} | Train Acc: {train_accuracy:.4f} | Test Acc: {test_accuracy:.4f}\")\n    print(f\"Train Precision: {train_precision:.4f} | Test Precision: {test_precision:.4f} | Train Recall: {train_recall:.4f} | Test Recall: {test_recall:.4f}\")\n    print(f\"Train F1 Score: {train_f1_score:.4f} | Test F1 Score: {test_f1_score:.4f} | Train AUC-ROC: {train_auc_roc_value:.4f} | Test AUC-ROC: {test_auc_roc_value:.4f}\")\n\nend_time = time.time()\nprint(f\"\\nTraining completed in {end_time - start_time:.2f} seconds.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-26T06:30:51.448609Z","iopub.execute_input":"2025-03-26T06:30:51.448870Z","iopub.status.idle":"2025-03-26T06:31:19.229212Z","shell.execute_reply.started":"2025-03-26T06:30:51.448839Z","shell.execute_reply":"2025-03-26T06:31:19.228353Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Plotting the metrics\nimport matplotlib.pyplot as plt\n\nepochs_range = range(1, epochs + 1)\nplt.figure(figsize=(20, 10))\n\nplt.subplot(2, 3, 1)\nplt.plot(epochs_range, train_losses, label='Train Loss')\nplt.plot(epochs_range, test_losses, label='Test Loss')\n\n# Plot Accuracy\nplt.subplot(2, 3, 2)\nplt.plot(epochs_range, train_accuracies, label='Train Accuracy')\nplt.plot(epochs_range, test_accuracies, label='Test Accuracy')\n\n\n# Plot Precision\nplt.subplot(2, 3, 3)\nplt.plot(epochs_range, train_precisions, label='Train Precision')\nplt.plot(epochs_range, test_precisions, label='Test Precision')\n\n# Plot Recall\nplt.subplot(2, 3, 4)\nplt.plot(epochs_range, train_recalls, label='Train Recall')\nplt.plot(epochs_range, test_recalls, label='Test Recall')\n\n# Plot F1 Score\nplt.subplot(2, 3, 5)\nplt.plot(epochs_range, train_f1_scores, label='Train F1 Score')\nplt.plot(epochs_range, test_f1_scores, label='Test F1 Score')\n\n\n# Plot AUC-ROC\nplt.subplot(2, 3, 6)\nplt.plot(epochs_range, train_auc_roc, label='Train AUC-ROC')\nplt.plot(epochs_range, test_auc_roc, label='Test AUC-ROC')\n\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-26T06:31:19.230050Z","iopub.execute_input":"2025-03-26T06:31:19.230309Z","iopub.status.idle":"2025-03-26T06:31:20.122482Z","shell.execute_reply.started":"2025-03-26T06:31:19.230289Z","shell.execute_reply":"2025-03-26T06:31:20.121491Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model_path = \"CandidateRanking.pth\"\ntorch.save(model.state_dict(), model_path)\nprint(f\"Full model saved at: {model_path}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-26T06:31:20.123322Z","iopub.execute_input":"2025-03-26T06:31:20.123696Z","iopub.status.idle":"2025-03-26T06:31:20.132730Z","shell.execute_reply.started":"2025-03-26T06:31:20.123663Z","shell.execute_reply":"2025-03-26T06:31:20.131828Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# num_features = X_train_tensor.shape[1]\n# hidden_units = 128\n\n# # Assuming `model` is your trained model\n# model_path = \"CandidateRankingModel_with_param.pth\"\n# torch.save({\n#     'model_state_dict': model.state_dict(),\n#     'num_features': num_features,\n#     'hidden_units': hidden_units,\n# }, model_path)\n\n# print(f\"Model and parameters saved at: {model_path}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-26T06:31:20.133690Z","iopub.execute_input":"2025-03-26T06:31:20.134009Z","iopub.status.idle":"2025-03-26T06:31:20.145124Z","shell.execute_reply.started":"2025-03-26T06:31:20.133978Z","shell.execute_reply":"2025-03-26T06:31:20.144275Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#  Import Libraries\nimport pandas as pd\nimport numpy as np\nfrom sklearn.preprocessing import StandardScaler, OneHotEncoder\nfrom sklearn.model_selection import train_test_split\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.nn.functional as F\nfrom sklearn.metrics.pairwise import cosine_similarity\n\n#  Load Dataset\nfile_path = '/kaggle/input/original-hiring-dataset/Hiring_dataset.csv'\ndf = pd.read_csv(file_path)\n\n#  Preprocessing\nX = df.drop(['HiringDecision'], axis=1)\ny = df['HiringDecision']\n\n#  Identify Numerical & Categorical Features\nnumerical_features = X.select_dtypes(include=['int64', 'float64']).columns.tolist()\ncategorical_features = X.select_dtypes(include=['object']).columns.tolist()\n\n#  Scale Numerical Features\nscaler = StandardScaler()\nX_numerical = scaler.fit_transform(X[numerical_features])\n\n#  Encode Categorical Features\nencoder = OneHotEncoder()\nX_categorical = encoder.fit_transform(X[categorical_features]).toarray()\n\n#  Combine Preprocessed Features\nX_preprocessed = np.hstack((X_numerical, X_categorical))\n\n#  Split Data\nX_train, X_test = train_test_split(X_preprocessed, test_size=0.2, random_state=42)\n\n# Convert to PyTorch tensors\nX_train_tensor = torch.tensor(X_train, dtype=torch.float32)\nX_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n\n#  Deep Learning Model (Autoencoder-like)\nclass ContentBasedRecommender(nn.Module):\n    def __init__(self, input_dim, embedding_dim=64):\n        super(ContentBasedRecommender, self).__init__()\n        self.fc1 = nn.Linear(input_dim, 128)\n        self.fc2 = nn.Linear(128, 64)\n        self.fc3 = nn.Linear(64, embedding_dim)\n        \n    def forward(self, x):\n        x = torch.relu(self.fc1(x))\n        x = torch.relu(self.fc2(x))\n        x = self.fc3(x)\n        return x\n\n#  Initialize Model\ninput_dim = X_train_tensor.shape[1]\nembedding_dim = 64\n\nmodel = ContentBasedRecommender(input_dim, embedding_dim)\noptimizer = optim.Adam(model.parameters(), lr=0.001)\ncriterion = nn.MSELoss()\n\n#  Contrastive Loss Function (Fixed)\ndef contrastive_loss(embeddings):\n    \"\"\"\n    Contrastive loss using cosine similarity in the embedding space.\n    \"\"\"\n    batch_size = embeddings.shape[0]\n\n    # Randomly select positive and negative samples\n    idx = torch.randperm(batch_size)\n\n    positive = embeddings\n    negative = embeddings[idx]\n\n    #  Cosine similarities\n    sim_pos = F.cosine_similarity(positive, positive)  # Similarities with itself (should be 1)\n    sim_neg = F.cosine_similarity(positive, negative)  # Similarities with random negatives\n\n    #  Contrastive loss calculation\n    loss = torch.mean(1 - sim_pos + sim_neg)\n    return loss\n\n# Training Loop\nepochs = 50\nbatch_size = 64\n\nfor epoch in range(epochs):\n    model.train()\n\n    for i in range(0, len(X_train_tensor), batch_size):\n        batch = X_train_tensor[i:i + batch_size]\n\n        optimizer.zero_grad()\n\n        # Forward pass\n        embeddings = model(batch)\n\n        # Contrastive loss (fixed)\n        loss = contrastive_loss(embeddings)\n\n        #  Backward pass\n        loss.backward()\n        optimizer.step()\n\n    if (epoch + 1) % 10 == 0:\n        print(f'Epoch [{epoch+1}/{epochs}], Loss: {loss.item():.4f}')\n\n# Get Embeddings\nmodel.eval()\ntrain_embeddings = model(X_train_tensor).detach().numpy()\ntest_embeddings = model(X_test_tensor).detach().numpy()\n\nprint(\"\\n Embeddings Generated Successfully!\")\nprint(\"Train Embeddings Shape:\", train_embeddings.shape)\nprint(\"Test Embeddings Shape:\", test_embeddings.shape)\n\n#  Recommendation System\ndef recommend_candidates(target_profile, top_n=5):\n    \"\"\"\n    Recommend top-N candidates based on similarity to the target profile.\n    \"\"\"\n    #  Preprocess Target Profile\n    target_numerical = scaler.transform(target_profile[numerical_features])\n    target_categorical = encoder.transform(target_profile[categorical_features]).toarray()\n    target_preprocessed = np.hstack((target_numerical, target_categorical))\n    \n    # Convert to PyTorch tensor\n    target_tensor = torch.tensor(target_preprocessed, dtype=torch.float32)\n\n    # Generate target embedding\n    with torch.no_grad():\n        target_embedding = model(target_tensor).detach().numpy()\n\n    # Calculate cosine similarities\n    similarities = cosine_similarity(target_embedding, test_embeddings)[0]\n\n    # Rank candidates by similarity\n    ranked_indices = np.argsort(similarities)[::-1]\n    top_candidates = ranked_indices[:top_n]\n\n    #  Prepare Recommendation DataFrame\n    recommendations = pd.DataFrame({\n        'Candidate_Index': top_candidates,\n        'Similarity_Score': similarities[top_candidates]\n    })\n    \n    return recommendations\n\n#  Sample Target Profile\nsample_target = pd.DataFrame({\n    'Age': [35],\n    'Gender': ['Male'],\n    'EducationLevel': [\"Master's\"],\n    'ExperienceYears': [8],\n    'PreviousCompanies': [3],\n    'DistanceFromCompany': [20],\n    'InterviewScore': [75],\n    'SkillScore': [80],\n    'PersonalityScore': [85],\n    'RecruitmentStrategy': ['Aggressive']\n})\n\n# Recommend Candidates\nrecommendations = recommend_candidates(sample_target, top_n=5)\nprint(\"\\nðŸ”¥ Top Recommended Candidates:\")\nprint(recommendations)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}